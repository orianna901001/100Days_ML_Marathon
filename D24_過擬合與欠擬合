一個適當的機器學習工作流程包括：
    切割訓練集與測試集
    資料視覺化與前處理
    尋找適合的模型
    調整模型超參數
    使用適當的指標評估模型
    交叉驗證模型

Bias-Variance Tradeoff
以打靶例子解釋方差與偏差之間的關聯性，假設我們發射十次，其中的精就表示這十個把面上的點彼此間距離都相當近，也就是我的方差非常低(low variance)，而所謂的準就表示這十個點都離準心很近，也就是我們的偏差非常低(low bias)。

Underfitting: 過於簡單的模型使得預測結果彈性不高，訓練集與測試集表現都不好。low variance (high bias)，或是加入太多的 L1/L2 正則化限制模型預測能力。
Overfitting: 過於複雜的模型使得訓練集完整的被擬合，因此訓練集表現極好，但測試集表現不佳。high variance (low bias)。

Error from Bias：偏差(bias)就是模型的預測與真實值之間的差異，當一個模型訓練結果偏差過大我們可以得知該模型過於簡單。無論搜集再多的資料，線性的模型永遠無法擬合非線性的曲線，大的 bias，小的 variance稱為欠擬合
Error from Variance：方差(variance)是指你的模型對於資料集的敏感程度，當你的訓練資料有需多的隨機誤差或是離群值時，我們又把這些異常值全部擬合進模型裡面，導致學出來的模型過於複雜同時降低泛化能力，對於未知的資料預測的能力就會很差，同時造就了很高的 variance error。因此這樣的結果我們稱為過度擬合。

解決欠擬和：1. 增加輸入特徵或特徵工程 2.提高模型複雜度
解決過度擬和： 
  1. 搜集更多訓練資料
        增加訊練集的資料量是有效控制 variance 的方法，並且不會增加 bias。
  2. 模型添加 Regularization
        在損失函數中增加一些限制式，降低模型複雜。
  3. 交叉驗證
        從訓練集中切出驗證集，並挑出好的模型。而不是從測試集中求最小 error。
  4. Early Stopping
        設定當模型連續幾帶都無法改善 error，就立即終止訓練。
   5. Ensembling
        透過訓練多個模型，並取得每個模型預測並平均作為最終輸出。

