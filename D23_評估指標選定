評估指標 - 迴歸：
觀察「預測值」 (Prediction) 與「實際值」 (Ground truth) 的差距。
MAE (平均絕對誤差): 把所有誤差求平方後，求其平均。能反映預測值誤差的實際情況。又稱 L1 損失。
MSE (均方誤差): 把所有誤差求平方後，求其平均。由於有平方，會將誤差放大，因此適合梯度計算。又稱 L2 損失
RMSE (均方根誤差): 將 MSE 加了個根號，這樣數量級上比較直觀。
R2_score: 解釋模型輸出的變異程度有多少。如果 R2 分數很高越接近 1，表示模型的解釋能力很高。

在預測連續性數值輸出的迴歸模型中，大家往往會直接呼叫模型提供的評估方法直接計算 score(R2 分數)，又稱判定係數 (coefficient of determination)。
所謂的判定係數是輸入特徵 (x) 去解釋輸出 (y) 的變異程度有多少，其計算公式是：迴歸模型的變異量 (SSR)/總變異量 (TSS) 。
TSS 就是計算總變異，把每個實際的 y 減去平均數的平方加總起來。
而 SSR 就是把所有的模型預測 y 減去平均數的平方加總起來。

評估指標 - 分類
Accuracy： 一般最常見的評估方法。
Precision： 通常在不容錯誤的情況下會以作為主要評估指標，例如手機臉部解鎖的模型。
Recall： 寧可誤殺也不放過任何一個，例如癌症檢測模型。
F1 Score： Precision 與 Recall 的綜合指標。

混淆矩陣 (Confusion Matrix)
TP(True Positive): 正確預測成功的正樣本，例如真實答案(Ground True)是貓，成功的把一張貓的照片預測成貓，即為TP。
TN(True Negative): 正確預測成功的負樣本，成功的把一張狗的照片標示成不是貓，即為TN。
FP(False Positive): 錯誤預測成正樣本，實際上為負樣本，例如：錯誤的把一張狗的照片預測成貓。
FN(False Negative): 錯誤預測成負樣本，實際上為正樣本，例如：錯誤的把一張貓的照片預測成不是貓。

ROC 與 AUC 評估
ROC(Receiver Operator Characteristic Curve) 曲線呈現分類器在效益（真陽性率）與成本（偽陽性率）之間的相對關係。其中點（0,1）代表完美分類，代表效益最大，成本最低。所以ROC曲線越靠近左上方越好。FPR為X軸；TPR為Y軸。
AUC (Area Under Curve) 代表在 ROC 曲線下的面積，能表示分類器預測能力的一項常用的統計值。當AUC = 1時，代表分類器非常完美，但這畢竟是理想狀況。當AUC > 0.5時，代表分類器分類效果優於隨機猜測，模型有預測價值。當AUC = 0.5時，代表分類器分類效果與隨機猜測相同，模型無預測價值。
F1-Score： Precision, Recall 的調和平均數。
    Precision: 模型判定瑕疵，樣本確實為瑕疵的比例(被分類器挑選(selected)出來的正體樣本究竟有多少是真正的樣本)。
    Recall: 模型判定的瑕疵，佔樣本所有瑕疵的比例(在全部真正的樣本裡面分類器選了多少個)。以瑕疵檢測為例，若為 recall=1 則代表所有瑕疵都被找到。
      T,F 代表模型預測對或錯，P/N 代表模型預測結果。
      例如 True Positive 代表模型預測是正樣本且預測正確。
