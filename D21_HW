牛頓法概述：牛頓法（Newton’s Method）是一種在實數域與複數域上，透過函數𝑓(𝑥)的泰勒級數前幾項近似，來迭代求解方程 𝑓(𝑥)=0

牛頓優點：
收斂速度快：在目標函數光滑且初始點合理時，可達到二次收斂，誤差迅速減小。
自適應步長：更新公式內含 Hessian 反演，自動估計最適步長，無需手動調整學習率。
方向與步幅兼顧：同時利用一階與二階資訊，搜尋方向更準確，往往能更快到達極值附近。

牛頓缺點：
計算成本高：每次迭代需計算 Hessian 矩陣並求逆，對高維問題極度耗時且耗記憶體。
對 Hessian 要求嚴格：若 Hessian 不正定或接近奇異，難以直接使用；需額外修正（如阻尼、近似矩陣）。
對初始點敏感：若選在函數形狀複雜或遠離解的位置，可能收斂緩慢、發散，甚至落入錯誤臨界點。

收斂階數差異
牛頓法為 二階收斂：當迭代點已相當接近真實根時，誤差大約每次平方級別縮小。
梯度下降法為 一階收斂：誤差以線性速度下降，通常需要更多步驟才能達到相同精度。

局部近似模型差異
牛頓法：在當前點利用 二次曲面（含 Hessian 資訊）去擬合目標函數的局部形狀，既考慮方向，也估計最佳步長。
梯度下降法：僅以 平面（梯度方向）去擬合，雖然計算簡單，但對步長估計較粗略。

補充公式：https://github.com/wizardforcel/data-science-notebook/blob/master/ml/BAT_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_1000_%E9%A2%98/301-400.md
